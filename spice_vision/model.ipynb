{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Normalize, RandomResizedCrop, ToTensor\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from .utils._logger import logger\n",
    "from .utils._validation import config_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class\n",
    "class FoodDataset:\n",
    "    \"\"\"\n",
    "    A custom dataset class for the food image classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        \"\"\"\n",
    "        self.dataset = load_dataset(config_args.dataset_path)\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(\n",
    "            config_args.base_model, use_fast=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            self.labels = self.dataset[\"train\"].features[\"label\"].names\n",
    "            label2id, id2label = dict(), dict()\n",
    "\n",
    "            for i, label in enumerate(self.labels):\n",
    "                label2id[label] = i\n",
    "                id2label[i] = label\n",
    "\n",
    "            self.label2id = label2id\n",
    "            self.id2label = id2label\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing labels: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the image and label.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            example = self.dataset[idx]\n",
    "            image = example[\"image\"]\n",
    "            label = example[\"label\"]\n",
    "\n",
    "            pixel_values = self.image_processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "            return {\"pixel_values\": pixel_values, \"label\": label}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing item at index {idx}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = FoodDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "from torchvision.transforms.transforms import Normalize\n",
    "\n",
    "\n",
    "def augment_images(example):\n",
    "    \"\"\"\n",
    "    Augments images with defined values.\n",
    "\n",
    "    Args:\n",
    "        example: Use over dataset\"s .with_transform() method.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        normalize: Normalize = Normalize(\n",
    "            mean=food.image_processor.image_mean, std=food.image_processor.image_std\n",
    "        )\n",
    "\n",
    "        size = (\n",
    "            food.image_processor.size[\"shorted_edge\"]\n",
    "            if \"shorted_edge\" in food.image_processor.size\n",
    "            else (\n",
    "                food.image_processor.size[\"height\"],\n",
    "                food.image_processor.size[\"width\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Data augmentation\n",
    "        _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
    "\n",
    "        example[\"pixel_values\"] = [\n",
    "            _transforms(img.convert(\"RGB\")) for img in example[\"image\"]\n",
    "        ]  # Similar to input_ids in NLP\n",
    "        del example[\"image\"]\n",
    "\n",
    "        return example\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transform images failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_augment = food.dataset.with_transform(augment_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b91919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def compute_metrics(eval_pred) -> dict:\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for the image classification task.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: The prediction and reference from the Trainer.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions, references = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "        return evaluate.load(\"accuracy\").compute(\n",
    "            predictions=predictions, references=references\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing metrics: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def load_model(model_name: str) -> AutoModelForImageClassification:\n",
    "    \"\"\"\n",
    "    Loads the pre-trained image classification model.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the pre-trained model.\n",
    "\n",
    "    Returns:\n",
    "        AutoModelForImageClassification: The pre-trained model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(food.labels),\n",
    "            id2label=food.id2label,\n",
    "            label2id=food.label2id,\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_arguments(output_dir: str) -> TrainingArguments:\n",
    "    \"\"\"\n",
    "    Sets the TrainingArguments object.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The directory to save the trained model.\n",
    "\n",
    "    Returns:\n",
    "        TrainingArguments: The TrainingArguments object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            remove_unused_columns=False,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=5e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            gradient_accumulation_steps=4,\n",
    "            # num_train_epochs=2,\n",
    "            max_steps=20,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "        return args\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error setting training arguments: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def create_model(\n",
    "    model: AutoModelForImageClassification, args: TrainingArguments\n",
    ") -> Trainer:\n",
    "    \"\"\"\n",
    "    Trains the image classification model.\n",
    "\n",
    "    Args:\n",
    "        model (AutoModelForImageClassification): The pre-trained model.\n",
    "        args (TrainingArguments): The TrainingArguments object.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: The trained Trainer object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=food_augment[\"train\"],\n",
    "            eval_dataset=food_augment[\"test\"],\n",
    "            tokenizer=food.image_processor,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        return trainer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error training model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e514fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(save_name: str):\n",
    "    \"\"\"\n",
    "    Orchestrates the food classification training process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = load_model(config_args.base_model)\n",
    "        args = set_training_arguments(config_args.output_path)\n",
    "\n",
    "        trainer = create_model(model, args)\n",
    "        trainer.train()\n",
    "\n",
    "        trainer.save_model(config_args.output_path + \"\\\\\" + save_name)\n",
    "        logger.info(f\"Training completed. Model saved to {config_args.output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b55861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path: str, load_name: str) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns image predictions.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path of custom image.\n",
    "        load_name: Name of the saved model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\n",
    "        \"image-classification\",\n",
    "        config_args.output_path + \"\\\\\" + load_name,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    )\n",
    "    image = Image.open(image_path)\n",
    "    return pipe(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
